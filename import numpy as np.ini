import numpy as np
import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
import seaborn as sns
import matplotlib.pyplot as plt

# 피처 이름 파일 읽어오기
feature_name_df = pd.read_csv('./11장_data/UDI_HAR_Dataset/UCI_HAR_Dataset/features.txt', sep='\s+', header=None, names=['index', 'feature_name'], engine='python')
print(feature_name_df.head())
print(feature_name_df.shape)

# index 제거하고, feature_name만 리스트로 저장
feature_name = feature_name_df.iloc[:, 1].values.tolist()
print(feature_name[:5])

# X_train 데이터 읽어오기
X_train = pd.read_csv('./11장_data/UDI_HAR_Dataset/UCI_HAR_Dataset/train/X_train.txt', delim_whitespace=True, header=None, encoding='latin-1')
X_train.columns = feature_name

# Y_train 데이터 읽어오기
Y_train = pd.read_csv('./11장_data/UDI_HAR_Dataset/UCI_HAR_Dataset/train/y_train.txt', sep='\s+', header=None, names=['action'], engine='python')

# Y_test 데이터 읽어오기
Y_test = pd.read_csv('./11장_data/UDI_HAR_Dataset/UCI_HAR_Dataset/test/y_test.txt', sep='\s+', header=None, names=['action'], engine='python')

print(X_train.shape, Y_train.shape, Y_test.shape)
print(X_train.head())
print(Y_train['action'].value_counts())

# 결정 트리 분류 분석: 모델 생성
dt_HAR = DecisionTreeClassifier(random_state=156)

# 결정 트리 분류 분석: 모델 훈련
dt_HAR.fit(X_train, Y_train)

# 결정 트리 분류 분석: 평가 데이터에 예측 수행
Y_predict = dt_HAR.predict(X_test)

# 예측 정확도 계산 및 결과 출력
accuracy = accuracy_score(Y_test, Y_predict)
print('결정 트리 예측 정확도: {0:.4f}'.format(accuracy))
print('결정 트리의 현재 하이퍼 매개변수:', dt_HAR.get_params())

# 하이퍼 매개변수 튜닝
params = {'max_depth': [8, 10, 12, 16, 20, 24]}
grid_cv = GridSearchCV(dt_HAR, param_grid=params, scoring='accuracy', cv=5, return_train_score=True)
grid_cv.fit(X_train, Y_train)
cv_results_df = pd.DataFrame(grid_cv.cv_results_)
print(cv_results_df[['param_max_depth', 'mean_test_score', 'mean_train_score']])
print('최고 평균 정확도: {0:.4f}, 최적 하이퍼 매개변수: {1}'.format(grid_cv.best_score_, grid_cv.best_params_))

params = {'max_depth': [8, 16, 20], 'min_samples_split': [8, 16, 24]}
grid_cv = GridSearchCV(dt_HAR, param_grid=params, scoring='accuracy', cv=5, return_train_score=True)
grid_cv.fit(X_train, Y_train)
cv_results_df = pd.DataFrame(grid_cv.cv_results_)
print(cv_results_df[['param_max_depth', 'param_min_samples_split', 'mean_test_score', 'mean_train_score']])
print('최고 평균 정확도: {0:.4f}, 최적 하이퍼 매개변수: {1}'.format(grid_cv.best_score_, grid_cv.best_params_))

# 최적 모델을 사용한 예측 및 정확도 계산
best_dt_HAR = grid_cv.best_estimator_
best_Y_predict = best_dt_HAR.predict(X_test)
best_accuracy = accuracy_score(Y_test, best_Y_predict)
print('best 결정 트리 예측 정확도: {0:.4f}'.format(best_accuracy))

# 특성 중요도 시각화
feature_importance_values = best_dt_HAR.feature_importances_
feature_importance_values_s = pd.Series(feature_importance_values, index=X_train.columns)
feature_top10 = feature_importance_values_s.sort_values(ascending=False)[:10]

plt.figure(figsize=(10, 5))
plt.title('Feature Top 10')
sns.barplot(x=feature_top10, y=feature_top10.index)
plt.show()

